{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ch06_GAN_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "d_inputs (InputLayer)        [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "d_flatten (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "d_dense_1 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "d_relu_1 (LeakyReLU)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "d_dense_2 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "d_relu_2 (LeakyReLU)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "d_validity (Dense)           (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建置並編譯鑑別器(discriminator)\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow import keras\n",
    "\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "\n",
    "d_inputs = keras.Input(shape=(img_rows,img_cols), name=\"d_inputs\")\n",
    "d = layers.Flatten(name=\"d_flatten\")(d_inputs)\n",
    "d = layers.Dense(units=512, name=\"d_dense_1\")(d)\n",
    "d = layers.LeakyReLU(alpha=0.2, name=\"d_relu_1\")(d)\n",
    "d = layers.Dense(units=256, name=\"d_dense_2\")(d)\n",
    "d = layers.LeakyReLU(alpha=0.2, name=\"d_relu_2\")(d)\n",
    "d_validity = layers.Dense(units=1, activation=\"sigmoid\", name=\"d_validity\")(d)\n",
    "\n",
    "d_model = models.Model(d_inputs, d_validity, name=\"model_discriminator\")\n",
    "d_model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "d_model.summary()\n",
    "\n",
    "d_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 28, 28)            581776    \n",
      "_________________________________________________________________\n",
      "model_discriminator (Model)  (None, 1)                 533505    \n",
      "=================================================================\n",
      "Total params: 1,115,281\n",
      "Trainable params: 580,752\n",
      "Non-trainable params: 534,529\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g_model = models.Sequential()\n",
    "g_model.add(layers.Dense(units=128, name=\"g_dense_1\"))\n",
    "g_model.add(layers.LeakyReLU(alpha=0.2, name=\"g_relu_1\"))\n",
    "g_model.add(layers.Dense(units=256, name=\"g_dense_2\"))\n",
    "g_model.add(layers.LeakyReLU(alpha=0.2, name=\"g_relu_2\"))\n",
    "g_model.add(layers.Dense(units=512, name=\"g_dense_3\"))\n",
    "g_model.add(layers.LeakyReLU(alpha=0.2, name=\"g_relu_3\"))\n",
    "g_model.add(layers.BatchNormalization(name=\"g_normal\"))\n",
    "g_model.add(layers.Dense(units=(img_rows*img_cols), activation=\"tanh\", name=\"g_dense_4\"))\n",
    "g_model.add(layers.Reshape(target_shape=(img_rows,img_cols), name=\"g_validity\"))\n",
    "\n",
    "# 輸入生成器生成之圖片到鑑別器中\n",
    "z = keras.Input(shape=(100,))\n",
    "img = g_model(z)\n",
    "validity = d_model(img)\n",
    "\n",
    "#透過訓練使生成器生成的圖片足以混淆鑑別器的判斷\n",
    "c_model = models.Model(z, validity)\n",
    "c_model.compile(loss='binary_crossentropy', optimizer=\"adam\")\n",
    "c_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "# 讀取mnist資料庫\n",
    "(x_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train[:6000]\n",
    "# 調整目標樣本型態，訓練集資料\n",
    "x_train = x_train / 127.5 - 1.\n",
    "#x_train = np.expand_dims(x_train, axis=3)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# 設置生成對抗性事實(Adversarial ground truths)參數\n",
    "valid = np.ones((batch_size, 1))\n",
    "fake = np.zeros((batch_size, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.227261, acc.: 100.00%] [G loss: 0.427187]\n",
      "1 [D loss: 0.130242, acc.: 100.00%] [G loss: 0.448771]\n",
      "2 [D loss: 0.083774, acc.: 100.00%] [G loss: 0.486653]\n",
      "3 [D loss: 0.062856, acc.: 100.00%] [G loss: 0.519980]\n",
      "4 [D loss: 0.046663, acc.: 100.00%] [G loss: 0.550649]\n",
      "5 [D loss: 0.033222, acc.: 100.00%] [G loss: 0.539564]\n",
      "6 [D loss: 0.030694, acc.: 100.00%] [G loss: 0.707994]\n",
      "7 [D loss: 0.055229, acc.: 100.00%] [G loss: 0.766304]\n",
      "8 [D loss: 0.054027, acc.: 100.00%] [G loss: 0.779538]\n",
      "9 [D loss: 0.030094, acc.: 100.00%] [G loss: 1.009564]\n",
      "10 [D loss: 0.013447, acc.: 100.00%] [G loss: 1.221843]\n",
      "11 [D loss: 0.027757, acc.: 100.00%] [G loss: 1.123853]\n",
      "12 [D loss: 0.044351, acc.: 99.61%] [G loss: 0.976547]\n",
      "13 [D loss: 0.052555, acc.: 100.00%] [G loss: 1.052782]\n",
      "14 [D loss: 0.022306, acc.: 100.00%] [G loss: 1.077788]\n",
      "15 [D loss: 0.262606, acc.: 89.45%] [G loss: 0.806590]\n",
      "16 [D loss: 0.631722, acc.: 61.72%] [G loss: 0.579529]\n",
      "17 [D loss: 0.310540, acc.: 82.42%] [G loss: 0.723996]\n",
      "18 [D loss: 0.061290, acc.: 98.83%] [G loss: 1.083681]\n",
      "19 [D loss: 0.023294, acc.: 99.61%] [G loss: 1.047880]\n",
      "20 [D loss: 0.011223, acc.: 100.00%] [G loss: 1.423904]\n",
      "21 [D loss: 0.010247, acc.: 100.00%] [G loss: 1.500520]\n",
      "22 [D loss: 0.009167, acc.: 100.00%] [G loss: 1.245778]\n",
      "23 [D loss: 0.041630, acc.: 98.83%] [G loss: 1.328745]\n",
      "24 [D loss: 0.067639, acc.: 98.05%] [G loss: 0.971182]\n",
      "25 [D loss: 0.075254, acc.: 98.05%] [G loss: 1.301814]\n",
      "26 [D loss: 0.081056, acc.: 96.48%] [G loss: 1.476492]\n",
      "27 [D loss: 0.033032, acc.: 100.00%] [G loss: 1.593409]\n",
      "28 [D loss: 0.042143, acc.: 99.22%] [G loss: 1.457860]\n",
      "29 [D loss: 0.123636, acc.: 94.92%] [G loss: 1.378940]\n",
      "30 [D loss: 0.191946, acc.: 90.62%] [G loss: 1.690654]\n",
      "31 [D loss: 0.087263, acc.: 98.05%] [G loss: 1.987294]\n",
      "32 [D loss: 0.035711, acc.: 100.00%] [G loss: 2.801464]\n",
      "33 [D loss: 0.302920, acc.: 92.19%] [G loss: 2.042552]\n",
      "34 [D loss: 0.367584, acc.: 81.25%] [G loss: 2.002183]\n",
      "35 [D loss: 0.356063, acc.: 80.08%] [G loss: 2.122121]\n",
      "36 [D loss: 0.117334, acc.: 95.31%] [G loss: 2.750022]\n",
      "37 [D loss: 0.052745, acc.: 98.44%] [G loss: 3.310928]\n",
      "38 [D loss: 0.014648, acc.: 99.61%] [G loss: 3.536865]\n",
      "39 [D loss: 0.018390, acc.: 100.00%] [G loss: 4.242169]\n",
      "40 [D loss: 0.021405, acc.: 99.61%] [G loss: 4.307962]\n",
      "41 [D loss: 0.015107, acc.: 99.22%] [G loss: 4.000828]\n",
      "42 [D loss: 0.040411, acc.: 98.83%] [G loss: 3.930932]\n",
      "43 [D loss: 0.046301, acc.: 98.44%] [G loss: 3.613281]\n",
      "44 [D loss: 0.065184, acc.: 97.27%] [G loss: 3.561125]\n",
      "45 [D loss: 0.106205, acc.: 94.92%] [G loss: 3.554945]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x_train)//batch_size):\n",
    "    imgs = x_train[i*batch_size:(i+1)*batch_size]\n",
    "    \n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    # 生成批次大小數量的圖片\n",
    "    gen_imgs = g_model.predict(noise)\n",
    "\n",
    "    # 訓練鑑別器\n",
    "    d_loss_real = d_model.train_on_batch(imgs, valid)\n",
    "    d_loss_fake = d_model.train_on_batch(gen_imgs, fake)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "    \n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    \n",
    "    # 訓練生成器\n",
    "    g_loss = c_model.train_on_batch(noise, valid)\n",
    "    \n",
    "    print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (i, d_loss[0], 100*d_loss[1], g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "a = d_model.predict(x_train[12:13])\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[12])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        \n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        #訓練過程中圖像儲存\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
