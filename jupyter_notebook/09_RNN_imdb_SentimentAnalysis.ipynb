{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文字處理\n",
    "正、負評價判別\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, utils, layers, models, optimizers, metrics, losses\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "seed = 13\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "word_index = datasets.imdb.get_word_index()\n",
    "index_word = {v:k for k,v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape (2500,)\n",
      "y_train.shape (2500,)\n",
      "x_test.shape (2500,)\n",
      "y_test.shape (2500,)\n",
      "x_train shape: (2500, 80)\n",
      "x_test shape: (2500, 80)\n"
     ]
    }
   ],
   "source": [
    "top_words = 10000\n",
    "max_review_length = 80\n",
    "\n",
    "def data_scale_down(train, test, scale):\n",
    "    (x_train,y_train),(x_test,y_test) = train, test\n",
    "    num_train = len(x_train)\n",
    "    num_test = len(x_test)\n",
    "    train_size = num_train // scale\n",
    "    test_size = num_test // scale\n",
    "    x_train, y_train = x_train[:train_size], y_train[:train_size]\n",
    "    x_test, y_test = x_test[:test_size], y_test[:test_size]\n",
    "    return (x_train,y_train), (x_test,y_test)\n",
    "\n",
    "def imdb_dataset():\n",
    "    (x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=top_words)\n",
    "    (x_train,y_train), (x_test,y_test) = data_scale_down((x_train,y_train), (x_test,y_test),10)\n",
    "    print(\"x_train.shape\",x_train.shape)\n",
    "    print(\"y_train.shape\",y_train.shape)\n",
    "    print(\"x_test.shape\",x_test.shape)\n",
    "    print(\"y_test.shape\",y_test.shape)\n",
    "    x_train = sequence.pad_sequences(x_train, maxlen=max_review_length)\n",
    "    x_test = sequence.pad_sequences(x_test, maxlen=max_review_length)\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print('x_test shape:', x_test.shape)\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = imdb_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train:  1\n",
      "\n",
      "x_train:\n",
      "[  15  256    4    2    7 3766    5  723   36   71   43  530  476   26\n",
      "  400  317   46    7    4    2 1029   13  104   88    4  381   15  297\n",
      "   98   32 2071   56   26  141    6  194 7486   18    4  226   22   21\n",
      "  134  476   26  480    5  144   30 5535   18   51   36   28  224   92\n",
      "   25  104    4  226   65   16   38 1334   88   12   16  283    5   16\n",
      " 4472  113  103   32   15   16 5345   19  178   32]\n",
      "\n",
      "max_review_length\n",
      "[15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "\n",
      "origin data\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "(x, y), (x_t, y_t) = datasets.imdb.load_data(num_words=top_words)\n",
    "print(\"y_train: \", y_train[0])\n",
    "print(\"\\nx_train:\")\n",
    "print(x_train[0])\n",
    "print(\"\\nmax_review_length\")\n",
    "print(x[0][-max_review_length:])\n",
    "print(\"\\norigin data\")\n",
    "print(x[0])\n",
    "#del x,y,x_t,y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:\n",
      "for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an \n",
      "\n",
      "origin data:\n",
      "the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an "
     ]
    }
   ],
   "source": [
    "print(\"x_train:\")\n",
    "for i in range(len(x_train[0])):\n",
    "    print(index_word[x_train[0][i]],end=\" \")\n",
    "print()\n",
    "print(\"\\norigin data:\")\n",
    "for i in range(len(x[0])):\n",
    "    print(index_word[x[0][i]],end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diction_size: 88584\n",
      "example index 1-11\n",
      "the and a of to is br in it i "
     ]
    }
   ],
   "source": [
    "print(\"diction_size:\",len(index_word))\n",
    "print(\"example index 1-11\")\n",
    "for i in range(1,11):\n",
    "    print(index_word[i], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del RNN\n",
    "class RNN(models.Model):\n",
    "    def __init__(self, units, num_classes, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.units = units\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.model = self.create_model()\n",
    "        \n",
    "        # self.cells = [keras.layers.LSTMCell(units) for _ in range(num_layers)]\n",
    "        # self.rnn = keras.layers.RNN(self.cells, unroll=True)\n",
    "        # self.cells = (keras.layers.LSTMCell(units) for _ in range(num_layers))\n",
    "        # #\n",
    "        # self.rnn = keras.layers.RNN(self.cells, return_sequences=True, return_state=True)\n",
    "        # self.rnn = keras.layers.LSTM(units, unroll=True)\n",
    "        # self.rnn = keras.layers.StackedRNNCells(self.cells)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        outputs = self.model(inputs)\n",
    "        return outputs\n",
    "    \n",
    "    def create_model(self):\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Input(shape=(max_review_length,)))\n",
    "        model.add(layers.Embedding(input_dim=top_words, output_dim=100))# , input_length=max_review_length\n",
    "        model.add(layers.LSTM(units=self.units, return_sequences=True))\n",
    "        model.add(layers.LSTM(units=self.units))\n",
    "        model.add(layers.Dense(units=1)) # , activation=\"softmax\"\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 64\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "model = RNN(units, num_classes, num_layers=2)\n",
    "#model.build(input_shape=(None, max_review_length, ))\n",
    "model.compile(optimizer=optimizers.Adam(0.05),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2500 samples, validate on 2500 samples\n",
      "2500/2500 [==============================] - 44s 18ms/sample - loss: 0.7140 - accuracy: 0.4996 - val_loss: 0.6885 - val_accuracy: 0.5248\n",
      "2500/1 - 7s - loss: 0.6732 - accuracy: 0.5248\n",
      "Final test loss 0.6885 and accuracy 0.5248 :\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "              validation_data=(x_test, y_test), verbose=1)\n",
    "    scores = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=2)\n",
    "    print(\"Final test loss {:.4f} and accuracy {:.4f} :\".format(scores[0],scores[1]))\n",
    "    \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rnn_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_9 (Sequential)    (None, 1)                 1075329   \n",
      "=================================================================\n",
      "Total params: 1,075,329\n",
      "Trainable params: 1,075,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prdictions: -0.0631 -0.0124 0.0404 -0.0170 -0.0184 -0.0141 0.0659 -0.3010 0.0568 0.1267 \n",
      "labels:\t\t 1\t0\t0\t1\t0\t0\t1\t0\t1\t0\t"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test[0:10])\n",
    "print(\"prdictions:\",end=\" \")\n",
    "for i in range(10):\n",
    "    print(\"%.4f\"%predictions[i], end=\" \")\n",
    "print(\"\\nlabels:\\t\\t\", end=\" \")\n",
    "for i in range(10):\n",
    "    print(y_train[i], end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
