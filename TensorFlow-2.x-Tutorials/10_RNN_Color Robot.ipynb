{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, six, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, utils, layers, models, optimizers, losses, metrics\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import  urllib\n",
    "\n",
    "seed = 13\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data\\train.csv exists\n",
      ".\\data\\test.csv exists\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 3\n",
    "\n",
    "data_dir = os.path.join(\".\",\"data\")\n",
    "SOURCE_TRAIN_URL = \"https://raw.githubusercontent.com/random-forests/tensorflow-workshop/master/archive/extras/colorbot/data/train.csv\"\n",
    "SOURCE_TEST_URL = \"https://raw.githubusercontent.com/random-forests/tensorflow-workshop/master/archive/extras/colorbot/data/test.csv\"\n",
    "\n",
    "def color_dataset():\n",
    "    #os.makedirs(data_dir, exists_ok=True)\n",
    "    train_data = load_dataset(data_dir=data_dir, url=SOURCE_TRAIN_URL, batch_size=batch_size)\n",
    "    eval_data = load_dataset(data_dir=data_dir, url=SOURCE_TEST_URL, batch_size=batch_size)\n",
    "    \n",
    "    return train_data, eval_data\n",
    "\n",
    "def parse(line):\n",
    "    # Each line of the dataset is comma-separated and formatted as\n",
    "    #    color_name, r, g, b\n",
    "    # `items` is a list [color_name, r, g, b].\n",
    "    items = tf.strings.split([line], sep=\",\").values\n",
    "    rgb = tf.strings.to_number(items[1:], out_type=tf.float32) / 255.\n",
    "    color_name = items[0]\n",
    "    chars = tf.one_hot(tf.io.decode_raw(color_name, tf.uint8), depth=256)\n",
    "    length = tf.cast(tf.shape(chars)[0], dtype=tf.int64)\n",
    "    return rgb, chars, length\n",
    "\n",
    "def load_dataset(data_dir, url, batch_size):\n",
    "    ## basename()   用于去掉目录的路径，只返回文件名\n",
    "    path = maybe_download(os.path.basename(url), data_dir, url)\n",
    "    # This chain of commands loads our data by:\n",
    "    #   1. skipping the header; (.skip(1))\n",
    "    #   2. parsing the subsequent lines; (.map(parse))\n",
    "    #   3. shuffling the data; (.shuffle(...))\n",
    "    #   3. grouping the data into padded batches (.padded_batch(...)).\n",
    "    dataset = tf.data.TextLineDataset(path).skip(1).map(parse).shuffle(\n",
    "        buffer_size=10000).padded_batch(batch_size, padded_shapes=([None], [None,None], []))    \n",
    "    return dataset    \n",
    "    \n",
    "def maybe_download(filename, work_directory, source_url):\n",
    "    if not tf.io.gfile.exists(work_directory):\n",
    "        tf.io.gfile.makedirs(work_directory)\n",
    "    filepath = os.path.join(work_directory, filename)\n",
    "    if not tf.io.gfile.exists(filepath):\n",
    "        temp_data, _ = urllib.request.urlretrieve(source_url)\n",
    "        tf.io.gfile.copy(temp_data, filepath)\n",
    "        with tf.io.gfile.GFile(filepath) as f:\n",
    "            size = f.size()\n",
    "            print(\"Successfully downloaded\", filename, size, \"bytes.\")\n",
    "    print(filepath,\"exists\")\n",
    "    return filepath\n",
    "\n",
    "train_data, test_data = color_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del RNNColorbot\n",
    "#del RNNCell\n",
    "class RNNColorbot(models.Model):\n",
    "    def __init__(self, rnn_cell_sizes, label_dimension, keep_prob):\n",
    "        super(RNNColorbot, self).__init__()\n",
    "        self.rnn_cell_sizes = rnn_cell_sizes\n",
    "        self.label_dimension = label_dimension\n",
    "        self.keep_prob = keep_prob\n",
    "        self.model = self.create_model()\n",
    "        \n",
    "    def call(self, inputs):        \n",
    "        outputs = self.model(inputs)\n",
    "        return outputs\n",
    "    \n",
    "    def create_model(self):\n",
    "        model = models.Sequential()        \n",
    "        cells = [RNNCell(units) for units in self.rnn_cell_sizes]        \n",
    "        model.add(layers.RNN(cells,input_shape=(22,256)))\n",
    "        model.add(layers.Dropout(rate=(1-self.keep_prob)))        \n",
    "        model.add(layers.Dense(units=self.label_dimension, activation=\"relu\"))\n",
    "        return model\n",
    "    \n",
    "class RNNCell(layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(RNNCell, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                      initializer=\"uniform\", name=\"kernel\")\n",
    "        self.recurrent_kernel = self.add_weight(shape=(self.units, self.units),\n",
    "                                      initializer=\"uniform\", name=\"recurrent_kernel\")\n",
    "        self.build = True\n",
    "        \n",
    "    def call(self, inputs, states):\n",
    "        prev_output = states[0]\n",
    "        h = K.dot(inputs, self.kernel)\n",
    "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
    "        return output, [output]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell_sizes = [256, 128]\n",
    "model = RNNColorbot(\n",
    "        rnn_cell_sizes=rnn_cell_sizes,\n",
    "        label_dimension=3,\n",
    "        keep_prob=0.7)\n",
    "model.compile(optimizer=optimizers.Adam(0.05),\n",
    "                  loss=\"mean_squared_error\",\n",
    "                  metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function _make_execution_function.<locals>.distributed_function at 0x0000025EF3D25B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "64/64 - 1s - loss: nan - accuracy: 0.6094\n",
      "Train on 64 samples\n",
      "WARNING:tensorflow:6 out of the last 15 calls to <function _make_execution_function.<locals>.distributed_function at 0x0000025EF3D25B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "64/64 - 1s - loss: nan - accuracy: 0.5156\n",
      "Train on 64 samples\n",
      "WARNING:tensorflow:7 out of the last 17 calls to <function _make_execution_function.<locals>.distributed_function at 0x0000025EF3D25B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "64/64 - 1s - loss: nan - accuracy: 0.5938\n",
      "Train on 64 samples\n",
      "64/64 - 0s - loss: nan - accuracy: 0.6406\n",
      "Train on 64 samples\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function _make_execution_function.<locals>.distributed_function at 0x0000025EF3D25B70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "64/64 - 1s - loss: nan - accuracy: 0.5625\n",
      "Train on 64 samples\n",
      "64/64 - 0s - loss: nan - accuracy: 0.5938\n",
      "Train on 64 samples\n",
      "64/64 - 0s - loss: nan - accuracy: 0.5625\n",
      "Train on 64 samples\n",
      "64/64 - 1s - loss: nan - accuracy: 0.4844\n",
      "Train on 64 samples\n",
      "64/64 - 1s - loss: nan - accuracy: 0.5312\n",
      "Train on 64 samples\n",
      "64/64 - 0s - loss: nan - accuracy: 0.6562\n",
      "Train on 64 samples\n",
      "64/64 - 0s - loss: nan - accuracy: 0.7188\n",
      "Train on 64 samples\n",
      "64/64 - 0s - loss: nan - accuracy: 0.5938\n",
      "Train on 64 samples\n",
      "64/64 - 0s - loss: nan - accuracy: 0.5938\n",
      "Train on 64 samples\n",
      "64/64 - 0s - loss: nan - accuracy: 0.5938\n",
      "Train on 64 samples\n",
      "64/64 - 0s - loss: nan - accuracy: 0.5938\n",
      "Train on 64 samples\n",
      "64/64 - 1s - loss: nan - accuracy: 0.6562\n",
      "Train on 64 samples\n",
      "64/64 - 0s - loss: nan - accuracy: 0.6094\n",
      "Train on 64 samples\n",
      "64/64 - 1s - loss: nan - accuracy: 0.5938\n",
      "Train on 14 samples\n",
      "14/14 - 1s - loss: nan - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for step, (labels, chars, sequence_length) in enumerate(train_data):\n",
    "    #chars = tf.transpose(chars, [1,0,2])\n",
    "    #batch_size = int(chars.shape[1])\n",
    "    model.fit(chars, labels, batch_size=batch_size,epochs=epochs, verbose=2) #\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
