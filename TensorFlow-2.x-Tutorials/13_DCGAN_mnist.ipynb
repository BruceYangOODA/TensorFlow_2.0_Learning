{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, utils, layers, models, losses, optimizers, metrics\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "#from scipy.misc import toimage 版本改為上面那個\n",
    "\n",
    "seed = 13\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape (6000, 28, 28)\n",
      "x_test.shape (6000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def data_scale_down(x_train, x_test, scale):\n",
    "    num_train = x_train.shape[0] // scale\n",
    "    num_test = x_test.shape[0] // scale\n",
    "    x_train = x_train[:num_train].astype(np.float32) // 255.\n",
    "    x_test = x_test[:num_train]\n",
    "    return x_train, x_test\n",
    "\n",
    "def mnist_dataset():\n",
    "    (x_train,_),(x_test,_) = datasets.mnist.load_data()\n",
    "    x_train, x_test = data_scale_down(x_train, x_test, scale=10)\n",
    "    print(\"x_train.shape\",x_train.shape)\n",
    "    print(\"x_test.shape\",x_test.shape)\n",
    "    return x_train, x_test\n",
    "\n",
    "x_train, x_test = mnist_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_size = 64\n",
    "\n",
    "def generator():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(units=3*3*filter_size, activation=\"relu\", name=\"hd_1\"))\n",
    "    model.add(layers.Reshape(target_shape=[3,3,filter_size], name=\"reshp\"))\n",
    "    model.add(layers.Conv2DTranspose(filters=filter_size//2, kernel_size=3, strides=2,\n",
    "                                     activation=\"relu\", padding=\"valid\", name=\"conv2\"))\n",
    "    model.add(layers.BatchNormalization(name=\"bn2\"))\n",
    "    model.add(layers.Conv2DTranspose(filters=filter_size//4, kernel_size=4, strides=2,\n",
    "                                     activation=\"relu\", padding=\"same\", name=\"conv3\"))\n",
    "    model.add(layers.BatchNormalization(name=\"bn3\"))\n",
    "    model.add(layers.Conv2DTranspose(filters=1, kernel_size=4, strides=2,\n",
    "                                     activation=\"tanh\", padding=\"same\", name=\"conv4\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "class Generator(models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = generator()        \n",
    "\n",
    "    def call(self, inputs):        \n",
    "        return self.model(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hd_1 (Dense)                 multiple                  58176     \n",
      "_________________________________________________________________\n",
      "reshp (Reshape)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2DTranspose)      multiple                  18464     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     multiple                  128       \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2DTranspose)      multiple                  8208      \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     multiple                  64        \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2DTranspose)      multiple                  257       \n",
      "=================================================================\n",
      "Total params: 85,297\n",
      "Trainable params: 85,201\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "hd_1 \t <tensorflow.python.keras.layers.core.Dense object at 0x000002408933F320>\n",
      "reshp \t <tensorflow.python.keras.layers.core.Reshape object at 0x000002408933F2B0>\n",
      "conv2 \t <tensorflow.python.keras.layers.convolutional.Conv2DTranspose object at 0x000002408933F4E0>\n",
      "bn2 \t <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002408A921BE0>\n",
      "conv3 \t <tensorflow.python.keras.layers.convolutional.Conv2DTranspose object at 0x00000240896CB8D0>\n",
      "bn3 \t <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000024089311E48>\n",
      "conv4 \t <tensorflow.python.keras.layers.convolutional.Conv2DTranspose object at 0x0000024089311C88>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "leraning_rate = 0.01\n",
    "is_training = True\n",
    "batch_size = 128\n",
    "z_dim = 100\n",
    "\n",
    "g_model = Generator()\n",
    "g_model.build(input_shape=(batch_size,z_dim))\n",
    "g_model.model.summary()\n",
    "for layer in g_model.model.layers:\n",
    "    print(layer.name,\"\\t\", layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    # input image is [-1, 28, 28, 1]\n",
    "    filters = 64\n",
    "    ker_size = 4\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=filters, kernel_size=ker_size, strides=2,\n",
    "                            activation=\"relu\", padding=\"same\", name=\"conv1\"))\n",
    "    model.add(layers.Conv2D(filters=filters*2, kernel_size=ker_size, strides=2,\n",
    "                            activation=\"relu\", padding=\"same\", name=\"conv2\"))\n",
    "    model.add(layers.BatchNormalization(name=\"bn2\"))\n",
    "    model.add(layers.Conv2D(filters=filters*4, kernel_size=ker_size, strides=2,\n",
    "                            activation=\"relu\", padding=\"same\", name=\"conv3\"))\n",
    "    model.add(layers.BatchNormalization(name=\"bn3\"))\n",
    "    model.add(layers.Flatten(name=\"flat\"))\n",
    "    model.add(layers.Dense(units=1, name=\"logits\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "class Discriminator(models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = discriminator()        \n",
    "\n",
    "    def call(self, inputs):        \n",
    "        return self.model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               multiple                  1088      \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               multiple                  131200    \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     multiple                  512       \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               multiple                  524544    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     multiple                  1024      \n",
      "_________________________________________________________________\n",
      "flat (Flatten)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "logits (Dense)               multiple                  4097      \n",
      "=================================================================\n",
      "Total params: 662,465\n",
      "Trainable params: 661,697\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "conv1 \t <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002408A9FA550>\n",
      "conv2 \t <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002408A9FA2E8>\n",
      "bn2 \t <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002408AA274E0>\n",
      "conv3 \t <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002408921DB00>\n",
      "bn3 \t <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002408A9909B0>\n",
      "flat \t <tensorflow.python.keras.layers.core.Flatten object at 0x000002408A9759B0>\n",
      "logits \t <tensorflow.python.keras.layers.core.Dense object at 0x000002408A9B3400>\n"
     ]
    }
   ],
   "source": [
    "d_model = Discriminator()\n",
    "d_model.build(input_shape=(batch_size, 28, 28, 1))\n",
    "d_model.model.summary()\n",
    "for layer in d_model.model.layers:\n",
    "    print(layer.name,\"\\t\", layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(batch_size*4).batch(batch_size).repeat()\n",
    "db_iter = iter(dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def celoss_ones(logits, smooth=0.0):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=logits, labels=tf.ones_like(logits)*(1.0 - smooth)\n",
    "    ))\n",
    "\n",
    "def celoss_zeros(logits, smooth=0.0):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=logits, labels=tf.zeros_like(logits)*(1.0 - smooth)\n",
    "    ))\n",
    "\n",
    "def d_loss_fn(model_g, model_d, input_noise, real_image):\n",
    "    fake_image = model_g(input_noise) # output shape (128,28,28,1)\n",
    "    d_real_logits = model_d(real_image) # output shape (128,1)\n",
    "    d_fake_logits = model_d(fake_image) # output shape (128,1)\n",
    "    \n",
    "    d_loss_real = celoss_ones(d_real_logits, smooth=0.1)\n",
    "    d_loss_fake = celoss_zeros(d_fake_logits, smooth=0.0)\n",
    "    loss = d_loss_real + d_loss_fake\n",
    "    return loss\n",
    "\n",
    "def g_loss_fn(model_g, model_d, input_noise):\n",
    "    fake_image = model_g(input_noise) # output shape (128,28,28,1)\n",
    "    d_fake_logits = model_d(fake_image) # output shape (128,1)\n",
    "    loss = celoss_ones(d_fake_logits, smooth=0.1)\n",
    "    return loss\n",
    "\n",
    "def save_result(val_out, val_block_size, image_fn, color_mode):\n",
    "    def preprocess(img):\n",
    "        img = ((img + 1.0) * 127.5).astype(np.uint8)\n",
    "        return img\n",
    "\n",
    "    preprocesed = preprocess(val_out)\n",
    "    final_image = np.array([])\n",
    "    single_row = np.array([])\n",
    "    for b in range(val_out.shape[0]):\n",
    "        # concat image into a row\n",
    "        if single_row.size == 0:\n",
    "            single_row = preprocesed[b, :, :, :]\n",
    "        else:\n",
    "            single_row = np.concatenate((single_row, preprocesed[b, :, :, :]), axis=1)\n",
    "\n",
    "        # concat image row to final_image\n",
    "        if (b+1) % val_block_size == 0:\n",
    "            if final_image.size == 0:\n",
    "                final_image = single_row\n",
    "            else:\n",
    "                final_image = np.concatenate((final_image, single_row), axis=0)\n",
    "\n",
    "            # reset single row\n",
    "            single_row = np.array([])\n",
    "\n",
    "    if final_image.shape[2] == 1:\n",
    "        final_image = np.squeeze(final_image, axis=2)\n",
    "    Image.fromarray(final_image, mode=color_mode).save(image_fn)\n",
    "    \n",
    "\n",
    "assets_dir = './images'\n",
    "if not os.path.isdir(assets_dir):\n",
    "    os.makedirs(assets_dir)\n",
    "val_block_size = 10\n",
    "val_size = val_block_size * val_block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 d loss: 1.4788918495178223 g loss: 0.6567821502685547\n",
      "19 d loss: 1.4440267086029053 g loss: 0.7294305562973022\n",
      "29 d loss: 1.3646976947784424 g loss: 0.9330277442932129\n",
      "39 d loss: 1.3927652835845947 g loss: 0.6837785840034485\n",
      "49 d loss: 1.3176616430282593 g loss: 0.843607485294342\n",
      "59 d loss: 1.4530634880065918 g loss: 1.5772510766983032\n",
      "69 d loss: 1.533296823501587 g loss: 0.8039431571960449\n",
      "79 d loss: 1.3543953895568848 g loss: 0.575875461101532\n",
      "89 d loss: 1.2793517112731934 g loss: 0.7645173668861389\n",
      "99 d loss: 1.4043993949890137 g loss: 1.1818479299545288\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "inputs_shape = [-1, 28, 28, 1]\n",
    "is_training = True\n",
    "\n",
    "g_optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "d_optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "#g_model.compile(optimizer=g_optimizer, loss=\"categorical_crossentropy\")\n",
    "#d_model.compile(optimizer=d_optimizer, loss=\"categorical_crossentropy\")\n",
    "\n",
    "def train():\n",
    "    for epoch in range(epochs):\n",
    "        batch_x = next(db_iter)\n",
    "        batch_x = tf.reshape(batch_x, shape=inputs_shape)\n",
    "        batch_x = batch_x * 2.0 -1.0 # -1 < px_value < 1\n",
    "        \n",
    "        # Sample random noise for G\n",
    "        batch_z = tf.random.uniform(shape=[batch_size, z_dim], minval=-1., maxval=1.)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            d_loss = d_loss_fn(g_model.model, d_model.model, batch_z, batch_x)\n",
    "        grads = tape.gradient(d_loss, d_model.model.trainable_variables)\n",
    "        d_optimizer.apply_gradients(zip(grads, d_model.model.trainable_variables))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            g_loss = g_loss_fn(g_model.model, d_model.model, batch_z)\n",
    "        grads = tape.gradient(g_loss, g_model.model.trainable_variables)\n",
    "        g_optimizer.apply_gradients(zip(grads, g_model.model.trainable_variables))\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print((epoch+1), 'd loss:', float(d_loss), 'g loss:', float(g_loss))\n",
    "            val_z = np.random.uniform(-1, 1, size=(val_size, z_dim))\n",
    "            fake_image = g_model.predict(val_z)\n",
    "            image_fn = os.path.join('images', 'gan-val-{:03d}.png'.format(epoch + 1))\n",
    "            save_result(fake_image, val_block_size, image_fn, color_mode='L')\n",
    "    print(\"finish training\")\n",
    "            \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
