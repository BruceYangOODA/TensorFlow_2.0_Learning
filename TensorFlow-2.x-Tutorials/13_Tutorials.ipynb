{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  tensorflow as tf\n",
    "from    tensorflow import keras\n",
    "\n",
    "\n",
    "class Generator(keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.n_f = 512\n",
    "        self.n_k = 4\n",
    "\n",
    "        # input z vector is [None, 100]\n",
    "        self.dense1 = keras.layers.Dense(3 * 3 * self.n_f)\n",
    "        self.conv2 = keras.layers.Conv2DTranspose(self.n_f // 2, 3, 2, 'valid')\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        self.conv3 = keras.layers.Conv2DTranspose(self.n_f // 4, self.n_k, 2, 'same')\n",
    "        self.bn3 = keras.layers.BatchNormalization()\n",
    "        self.conv4 = keras.layers.Conv2DTranspose(1, self.n_k, 2, 'same')\n",
    "        return\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # [b, 100] => [b, 3, 3, 512]\n",
    "        x = tf.nn.leaky_relu(tf.reshape(self.dense1(inputs), shape=[-1, 3, 3, self.n_f]))\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n",
    "        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))\n",
    "        x = tf.tanh(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.n_f = 64\n",
    "        self.n_k = 4\n",
    "\n",
    "        # input image is [-1, 28, 28, 1]\n",
    "        self.conv1 = keras.layers.Conv2D(self.n_f, self.n_k, 2, 'same')\n",
    "        self.conv2 = keras.layers.Conv2D(self.n_f * 2, self.n_k, 2, 'same')\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        self.conv3 = keras.layers.Conv2D(self.n_f * 4, self.n_k, 2, 'same')\n",
    "        self.bn3 = keras.layers.BatchNormalization()\n",
    "        self.flatten4 = keras.layers.Flatten()\n",
    "        self.dense4 = keras.layers.Dense(1)\n",
    "        return\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = tf.nn.leaky_relu(self.conv1(inputs))\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n",
    "        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))\n",
    "        x = self.dense4(self.flatten4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             multiple                  465408    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DT multiple                  1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc multiple                  1024      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DT multiple                  524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc multiple                  512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DT multiple                  2049      \n",
      "=================================================================\n",
      "Total params: 2,173,313\n",
      "Trainable params: 2,172,545\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Model: \"discriminator_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           multiple                  1088      \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           multiple                  131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc multiple                  512       \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           multiple                  524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc multiple                  1024      \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             multiple                  4097      \n",
      "=================================================================\n",
      "Total params: 662,465\n",
      "Trainable params: 661,697\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "0 d loss: 1.126291036605835 g loss: 29.957983016967773\n",
      "WARNING:tensorflow:Layer generator_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import  os\n",
    "import  numpy as np\n",
    "import  tensorflow as tf\n",
    "from    tensorflow import keras\n",
    "from PIL import Image\n",
    "#from    scipy.misc import toimage\n",
    "#from    gan import Generator, Discriminator\n",
    "\n",
    "\n",
    "\n",
    "def save_result(val_out, val_block_size, image_fn, color_mode):\n",
    "    def preprocess(img):\n",
    "        img = ((img + 1.0) * 127.5).astype(np.uint8)\n",
    "        return img\n",
    "\n",
    "    preprocesed = preprocess(val_out)\n",
    "    final_image = np.array([])\n",
    "    single_row = np.array([])\n",
    "    for b in range(val_out.shape[0]):\n",
    "        # concat image into a row\n",
    "        if single_row.size == 0:\n",
    "            single_row = preprocesed[b, :, :, :]\n",
    "        else:\n",
    "            single_row = np.concatenate((single_row, preprocesed[b, :, :, :]), axis=1)\n",
    "\n",
    "        # concat image row to final_image\n",
    "        if (b+1) % val_block_size == 0:\n",
    "            if final_image.size == 0:\n",
    "                final_image = single_row\n",
    "            else:\n",
    "                final_image = np.concatenate((final_image, single_row), axis=0)\n",
    "\n",
    "            # reset single row\n",
    "            single_row = np.array([])\n",
    "\n",
    "    if final_image.shape[2] == 1:\n",
    "        final_image = np.squeeze(final_image, axis=2)\n",
    "    Image.fromarray(final_image, mode=color_mode).save(image_fn)\n",
    "\n",
    "\n",
    "# shorten sigmoid cross entropy loss calculation\n",
    "def celoss_ones(logits, smooth=0.0):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n",
    "                                                                  labels=tf.ones_like(logits)*(1.0 - smooth)))\n",
    "\n",
    "\n",
    "def celoss_zeros(logits, smooth=0.0):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n",
    "                                                                  labels=tf.zeros_like(logits)*(1.0 - smooth)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def d_loss_fn(generator, discriminator, input_noise, real_image, is_trainig):\n",
    "    fake_image = generator(input_noise, is_trainig)\n",
    "    d_real_logits = discriminator(real_image, is_trainig)\n",
    "    d_fake_logits = discriminator(fake_image, is_trainig)\n",
    "\n",
    "    d_loss_real = celoss_ones(d_real_logits, smooth=0.1)\n",
    "    d_loss_fake = celoss_zeros(d_fake_logits, smooth=0.0)\n",
    "    loss = d_loss_real + d_loss_fake\n",
    "    return loss\n",
    "\n",
    "\n",
    "def g_loss_fn(generator, discriminator, input_noise, is_trainig):\n",
    "    fake_image = generator(input_noise, is_trainig)\n",
    "    d_fake_logits = discriminator(fake_image, is_trainig)\n",
    "    loss = celoss_ones(d_fake_logits, smooth=0.1)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    tf.random.set_seed(22)\n",
    "    np.random.seed(22)\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    assert tf.__version__.startswith('2.')\n",
    "\n",
    "\n",
    "    # hyper parameters\n",
    "    z_dim = 100\n",
    "    epochs = 100\n",
    "    batch_size = 128\n",
    "    learning_rate = 0.01\n",
    "    is_training = True\n",
    "\n",
    "    # for validation purpose\n",
    "    assets_dir = './images'\n",
    "    if not os.path.isdir(assets_dir):\n",
    "        os.makedirs(assets_dir)\n",
    "    val_block_size = 10\n",
    "    val_size = val_block_size * val_block_size\n",
    "\n",
    "    # load mnist data\n",
    "    (x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "    x_train = x_train.astype(np.float32) / 255.\n",
    "    db = tf.data.Dataset.from_tensor_slices(x_train).shuffle(batch_size*4).batch(batch_size).repeat()\n",
    "    db_iter = iter(db)\n",
    "    inputs_shape = [-1, 28, 28, 1]\n",
    "\n",
    "\n",
    "    # create generator & discriminator\n",
    "    generator = Generator()\n",
    "    generator.build(input_shape=(batch_size, z_dim))\n",
    "    generator.summary()\n",
    "    discriminator = Discriminator()\n",
    "    discriminator.build(input_shape=(batch_size, 28, 28, 1))\n",
    "    discriminator.summary()\n",
    "\n",
    "    # prepare optimizer\n",
    "    d_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
    "    g_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "\n",
    "        # no need labels\n",
    "        batch_x = next(db_iter)\n",
    "\n",
    "        # rescale images to -1 ~ 1\n",
    "        batch_x = tf.reshape(batch_x, shape=inputs_shape)\n",
    "        # -1 - 1\n",
    "        batch_x = batch_x * 2.0 - 1.0\n",
    "\n",
    "        # Sample random noise for G\n",
    "        batch_z = tf.random.uniform(shape=[batch_size, z_dim], minval=-1., maxval=1.)\n",
    "\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            d_loss = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)\n",
    "        grads = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "        d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            g_loss = g_loss_fn(generator, discriminator, batch_z, is_training)\n",
    "        grads = tape.gradient(g_loss, generator.trainable_variables)\n",
    "        g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "\n",
    "\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "\n",
    "            print(epoch, 'd loss:', float(d_loss), 'g loss:', float(g_loss))\n",
    "\n",
    "            # validation results at every epoch\n",
    "            val_z = np.random.uniform(-1, 1, size=(val_size, z_dim))\n",
    "            fake_image = generator(val_z, training=False)\n",
    "            image_fn = os.path.join('images', 'gan-val-{:03d}.png'.format(epoch + 1))\n",
    "            save_result(fake_image.numpy(), val_block_size, image_fn, color_mode='L')\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
